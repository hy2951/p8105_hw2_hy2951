P8105 Homework 2 — hy2951
================
Haochen Yu

``` r
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE, fig.path="figs/")

dir.create("data", showWarnings = FALSE)
dir.create("figs", showWarnings = FALSE)
list.files("data")
```

    ## character(0)

``` r
#libraries
library(tidyverse)
library(lubridate)
#pols-clean
pols <- read_csv("pols-month.csv", show_col_types = FALSE) |>
  separate(mon, into = c("year","month","day"), sep = "-", convert = TRUE) |>
  mutate(
    month = month(month, label = TRUE, abbr = FALSE),
    president = if_else(prez_gop == 1, "gop", "dem")
  ) |>
  select(year, month, president, everything(), -day, -prez_gop, -prez_dem) |>
  arrange(year, month)
#snp-clean
snp <- read_csv("snp.csv", show_col_types = FALSE) |>
  separate(date, into = c("m","d","y"), sep = "/", convert = TRUE) |>
  mutate(
    y = if_else(y < 50, 2000 + y, if_else(y < 100, 1900 + y, y)),
    month = month(m, label = TRUE, abbr = FALSE),
    year  = y
  ) |>
  transmute(year, month, close) |>
  arrange(year, month)
# unemp-tidy
unemployment <- read_csv("unemployment.csv", show_col_types = FALSE) |>
  pivot_longer(-Year, names_to = "mon", values_to = "unemployment_rate") |>
  mutate(
    mon   = str_sub(mon, 1, 3),
    mnum  = match(tolower(mon), tolower(month.abb)),
    month = month(mnum, label = TRUE, abbr = FALSE),
    year  = Year
  ) |>
  transmute(year, month, unemployment_rate) |>
  arrange(year, month)
#merge
pols_snp <- pols |> left_join(snp, by = c("year","month"))
p1_final <- pols_snp |> left_join(unemployment, by = c("year","month"))

dim_p1   <- dim(p1_final)
yr_min   <- min(p1_final$year, na.rm = TRUE)
yr_max   <- max(p1_final$year, na.rm = TRUE)

head(p1_final, 3)
```

    ## # A tibble: 3 × 11
    ##    year month    president gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem close
    ##   <dbl> <ord>    <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>
    ## 1  1947 January  dem            23      51     253      23      45     198    NA
    ## 2  1947 February dem            23      51     253      23      45     198    NA
    ## 3  1947 March    dem            23      51     253      23      45     198    NA
    ## # ℹ 1 more variable: unemployment_rate <dbl>

In this problem, I cleaned and merged three monthly datasets from
FiveThirtyEight:pols-month.csv（counts of national politicians by party,
and the party of the sitting president (gop/dem).）snp.csv（S&P stock
index closing values.）unemployment.csv（monthly U.S. unemployment
rates.） After cleaning, I merged them by year and month. The final
dataset has 822 rows and 11columns, covering years from 1947 to 2015.
Key variables include the party of the president, counts of
governors/senators/representatives, S&P closing values, and unemployment
rates.

``` r
#Problem 2 
library(tidyverse)   
library(readxl)     
library(lubridate)   
library(knitr)       

# Path 
path_tw <- "202509 Trash Wheel Collection Data.xlsx"
stopifnot(file.exists(path_tw))

# Minimal name repair: lower_snake, no blank names, unique
repair_names <- function(nms) {
  nms[is.na(nms) | nms == ""] <- paste0("x", seq_len(sum(is.na(nms) | nms == "")))
  nms <- tolower(nms)
  nms <- gsub("[^a-z0-9]+", "_", nms)
  nms <- gsub("^_|_$", "", nms)
  make.unique(nms, sep = "_")
}

# Reader for one sheet 
read_wheel <- function(sheet, label) {
  df <- read_excel(path_tw, sheet = sheet, skip = 1, .name_repair = "minimal")
  names(df) <- repair_names(names(df))

  # normalize key headers across versions
  nm <- names(df)
  dm <- nm[grepl("^dump|dumpster", nm, ignore.case = TRUE)]
  if (length(dm)) names(df)[match(dm[1], names(df))] <- "dumpster"

  dt <- nm[grepl("date", nm, ignore.case = TRUE)]
  if (length(dt)) names(df)[match(dt[1], names(df))] <- "date"

  # sports column can be "sports_balls" or just "sports"
  if ("sports" %in% names(df) && !"sports_balls" %in% names(df)) {
    names(df)[names(df) == "sports"] <- "sports_balls"
  }
  if (!"sports_balls" %in% names(df)) df$sports_balls <- NA_real_

  wt <- nm[grepl("weight.*ton", nm, ignore.case = TRUE)]
  if (length(wt) && wt[1] != "weight_tons") names(df)[match(wt[1], names(df))] <- "weight_tons"

  vol <- nm[grepl("volume.*yard", nm, ignore.case = TRUE)]
  if (length(vol) && vol[1] != "volume_cubic_yards") names(df)[match(vol[1], names(df))] <- "volume_cubic_yards"

  df |>
    mutate(
      date     = suppressWarnings(as_date(date)),
      dumpster = coalesce(as.integer(suppressWarnings(as.numeric(dumpster))), row_number())
    ) |>
    filter(!is.na(date)) |>
    mutate(
      year         = as.integer(year(date)),
      month        = month(date, label = TRUE, abbr = FALSE),
      sports_balls = as.integer(round(as.numeric(sports_balls))),
      wheel        = label
    ) |>
    select(any_of(c(
      "wheel","dumpster","date","year","month",
      "weight_tons","volume_cubic_yards",
      "plastic_bottles","polystyrene","cigarette_butts",
      "glass_bottles","plastic_bags","wrappers",
      "sports_balls","homes_powered"
    )))
}

# 
sheet_gwyn <- readxl::excel_sheets(path_tw)[grepl("^Gwyn", readxl::excel_sheets(path_tw), ignore.case = TRUE)][1]

# Read/clean three wheels
mr   <- read_wheel("Mr. Trash Wheel",       "Mr")
prof <- read_wheel("Professor Trash Wheel", "Professor")
gwyn <- read_wheel(sheet_gwyn,              "Gwynnda")

# Combine tidy dataset and compute required summaries
trash <- bind_rows(mr, prof, gwyn) |> arrange(wheel, date)

n_obs  <- nrow(trash)
n_vars <- ncol(trash)

prof_total_weight <- trash |>
  filter(wheel == "Professor") |>
  summarize(total_weight_tons = sum(weight_tons, na.rm = TRUE)) |>
  pull()

gwyn_cigs_jun2022 <- trash |>
  filter(wheel == "Gwynnda", month(date) == 6, year(date) == 2022) |>
  summarize(total_cigs = sum(cigarette_butts, na.rm = TRUE)) |>
  pull()

# Preview table 
kable(head(trash, 5), caption = "Preview of combined Trash Wheel data (2025 workbook)")
```

| wheel | dumpster | date | year | month | weight_tons | volume_cubic_yards | plastic_bottles | polystyrene | cigarette_butts | glass_bottles | plastic_bags | wrappers | sports_balls | homes_powered |
|:---|---:|:---|---:|:---|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|
| Gwynnda | 1 | 2021-07-03 | 2021 | July | 0.93 | 15 | 1200 | 360 | 3400 | NA | 1800 | NA | NA | 15.50000 |
| Gwynnda | 2 | 2021-07-07 | 2021 | July | 2.26 | 15 | 2000 | 240 | 3900 | NA | 2200 | NA | NA | 37.66667 |
| Gwynnda | 3 | 2021-07-07 | 2021 | July | 1.62 | 15 | 1800 | 270 | 2900 | NA | 2400 | NA | NA | 27.00000 |
| Gwynnda | 4 | 2021-07-16 | 2021 | July | 1.76 | 15 | 1000 | 180 | 2100 | NA | 1800 | NA | NA | 29.33333 |
| Gwynnda | 5 | 2021-07-30 | 2021 | July | 1.53 | 15 | 2100 | 240 | 4000 | NA | 2700 | NA | NA | 25.50000 |

Preview of combined Trash Wheel data (2025 workbook)

In this problem, I imported and cleaned the 2025 Trash Wheel Collection
Data for Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda. I
standardized column names, removed non-data rows, created year and month
from dates, and converted the sports balls column to integers. After
adding a wheel variable to identify each source, I combined the three
datasets into one tidy dataset with 1188 rows and 15 columns. From this
data, Professor Trash Wheel collected a total of 282.26 tons of trash,
and Gwynnda collected 1.812^{4} cigarette butts in June 2022.

``` r
# Problem 3
library(tidyverse)
library(lubridate)
library(knitr)

# Files 
zori_path <- "Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv"
zip_path  <- "Zip Codes.csv"
stopifnot(file.exists(zori_path), file.exists(zip_path))

# Simple name cleaner
clean_names <- function(x) {
  x <- tolower(x)
  x <- gsub("[^a-z0-9]+", "_", x)
  gsub("^_|_$", "", x)
}

# 1) Read ZORI and detect date columns
zori_raw <- read_csv(zori_path, show_col_types = FALSE)
names(zori_raw) <- clean_names(names(zori_raw))

if (!"regionname" %in% names(zori_raw)) stop("ZIP column RegionName not found in ZORI.")

# candidate non-id columns to test as dates
non_id <- setdiff(names(zori_raw),
                  c("regionname","regionid","city","state","statename","statecodefips",
                    "countyname","metroname","sizerank","size_rank"))

is_date_name <- function(nm) {
  !is.na(suppressWarnings(ymd(nm))) || !is.na(suppressWarnings(ym(nm)))
}
date_cols <- non_id[vapply(non_id, is_date_name, logical(1))]


if (length(date_cols) == 0) {
  date_cols <- non_id[grepl("^20\\d{2}", non_id)]
}
stopifnot(length(date_cols) > 0)

zori <- zori_raw |>
  rename(zip = regionname) |>
  pivot_longer(cols = all_of(date_cols), names_to = "date_str", values_to = "rent") |>
  mutate(
    date  = coalesce(suppressWarnings(ymd(date_str)), suppressWarnings(ym(date_str))),
    year  = year(date),
    month = month(date, label = TRUE, abbr = FALSE),
    zip   = as.integer(zip)
  ) |>
  select(zip, date, year, month, rent)

# 2) Read ZIP metadata and standardize borough & neighborhood
zip_meta <- read_csv(zip_path, show_col_types = FALSE)
names(zip_meta) <- clean_names(names(zip_meta))

# zip column
zip_candidates <- c("zip","zip_code","zipcode","zcta","zcta5")
zip_col <- zip_candidates[zip_candidates %in% names(zip_meta)][1]
if (is.na(zip_col)) stop("ZIP column not found in Zip Codes file.")
zip_meta <- zip_meta |> rename(zip = all_of(zip_col)) |> mutate(zip = as.integer(zip))


if ("borough" %in% names(zip_meta)) {
  # already good
} else if ("boro" %in% names(zip_meta)) {
  zip_meta <- zip_meta |> rename(borough = boro)
} else {
  county_candidates <- c("county","county_name")
  county_col <- county_candidates[county_candidates %in% names(zip_meta)][1]
  if (!is.na(county_col)) {
    zip_meta <- zip_meta |>
      mutate(borough = case_when(
        str_detect(tolower(.data[[county_col]]), "new york") ~ "Manhattan",
        str_detect(tolower(.data[[county_col]]), "kings")    ~ "Brooklyn",
        str_detect(tolower(.data[[county_col]]), "queens")   ~ "Queens",
        str_detect(tolower(.data[[county_col]]), "bronx")    ~ "Bronx",
        str_detect(tolower(.data[[county_col]]), "richmond") ~ "Staten Island",
        TRUE ~ NA_character_
      ))
  } else {
    zip_meta$borough <- NA_character_
  }
}

# neighborhood column: pick first available
hood_candidates <- c("neighborhood","neighborhood_name","nta_name",
                     "po_name","post_office_city","community","community_name")
hood_col <- hood_candidates[hood_candidates %in% names(zip_meta)][1]
if (!is.na(hood_col)) {
  zip_meta <- zip_meta |> mutate(neighborhood = .data[[hood_col]])
} else {
  zip_meta$neighborhood <- NA_character_
}

zip_meta <- zip_meta |> select(zip, borough, neighborhood) |> distinct()

# 3) Merge tidy data
nyc_rent <- zori |> left_join(zip_meta, by = "zip")

# 4) Summary
n_obs   <- nrow(nyc_rent)
n_zips  <- n_distinct(nyc_rent$zip)
n_hoods <- n_distinct(na.omit(nyc_rent$neighborhood))

# ZIPs present in metadata but not in ZORI
missing_zips <- setdiff(zip_meta$zip, unique(zori$zip))

# 5) Jan 2020 vs Jan 2021 change and top-10 drops
change_2020_21 <- nyc_rent |>
  filter(year %in% c(2020, 2021), month(date) == 1) |>
  transmute(zip, borough, neighborhood, yyyy = year(date), rent) |>
  pivot_wider(names_from = yyyy, values_from = rent) |>
  mutate(change = `2021` - `2020`) |>
  arrange(change)

top10_drop <- slice_head(change_2020_21, n = 10)

# 6) Preview table
kable(top10_drop, caption = "Top 10 ZIP codes with largest rent drop (Jan 2020 → Jan 2021)")
```

|   zip | borough   | neighborhood                  |     2020 |     2021 |    change |
|------:|:----------|:------------------------------|---------:|---------:|----------:|
| 10007 | Manhattan | Lower Manhattan               | 6334.211 | 5421.614 | -912.5966 |
| 10069 | Manhattan | NA                            | 4623.042 | 3874.918 | -748.1245 |
| 10009 | Manhattan | Lower East Side               | 3406.442 | 2692.187 | -714.2550 |
| 10016 | Manhattan | Gramercy Park and Murray Hill | 3731.135 | 3019.431 | -711.7045 |
| 10001 | Manhattan | Chelsea and Clinton           | 4108.098 | 3397.648 | -710.4499 |
| 10002 | Manhattan | Lower East Side               | 3645.416 | 2935.113 | -710.3028 |
| 10004 | Manhattan | Lower Manhattan               | 3149.658 | 2443.697 | -705.9608 |
| 10038 | Manhattan | Lower Manhattan               | 3573.201 | 2875.616 | -697.5853 |
| 10012 | Manhattan | Greenwich Village and Soho    | 3628.566 | 2942.344 | -686.2218 |
| 10010 | Manhattan | Gramercy Park and Murray Hill | 3697.284 | 3012.353 | -684.9304 |

Top 10 ZIP codes with largest rent drop (Jan 2020 → Jan 2021)

The combined dataset included 17516 observations, covering 149 unique
ZIP codes and 42 neighborhoods. Several ZIP codes in the metadata did
not appear in the Zillow dataset, likely because Zillow does not track
rents for areas with limited data. Comparing January 2020 and January
2021, the 10 ZIP codes with the largest rental price declines were all
located in Manhattan, with decreases between about \$685 and \$913. This
reflects the sharp pandemic-era rental downturn concentrated in dense,
central Manhattan neighborhoods.
